\documentclass[11pt,letterpaper]{article}
\oddsidemargin 0in
\evensidemargin 0in
\textwidth 6.5in
\topmargin -0.5in
\textheight 9.0in
\usepackage{hyperref}
\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{mathtools}
\newcommand{\blue}[1]{\textcolor{RoyalBlue}{#1}}
\newcommand{\fillme}[1]{\blue{\texttt{[Insert #1]}}}
\newcommand{\instructions}[1]{\blue{\textit{#1}}}
% uncomment the next two lines if you want the instructions to disappear.
\renewcommand{\instructions}[1]{}
\renewcommand{\fillme}[1]{}

\begin{document}

\title{CS446 Class Project Proposal - Stockit}
\author{dmcquil2@illinois.edu, mcconne7@illinois.edu}
\maketitle



\instructions{If you are taking CS446 for 4 hours credit, you need to
  do a research project.\\
This is a \LaTeX template for the initial proposal,  but should also give you a start on the final report.\\
The blue pieces of text  in this template are either instructions ({\tt$\backslash$instructions\{...\}}) or indicate where you need to fill in something ({\tt$\backslash$fillme\{...\}}).  
You should replace all the {\tt$\backslash$fillme\{...\}} commands with your own text.
To make the instructions disappear, please uncomment the 
\begin{center}
{\tt$\backslash$renewcommand\{$\backslash$instructions\}[1]\{\}}\\
%{\tt$\backslash$renewcommand\{$\backslash$fillme\}[1]\{\}}\\
\end{center}
lines in the preamble (just above {\tt $\backslash$begin\{document\}} of this .tex file) by removing the leading \% marks,
recompile (run \LaTeX again) and submit the PDF on Compass.\\
The template for the final report is at
\url{http://courses.engr.illinois.edu/cs446/Projects/CS446proj.tex}
(or
\url{http://courses.engr.illinois.edu/cs446/Projects/CS446proj.pdf}
for the pdf)
}
\section*{Task description}
  Stockit is an algorithm developed to forecast stock price changes from
  a given news article body. A successful algorithm will be one that provides
  a statistically significant advantage to predicting the percentage change
  in a stock price.
\instructions{Describe the task you want to tackle in your project.}

\section*{Background}
  There have been other attempts to predict stock market prices using
  machine learning. For example,
  \href{http://ailab.arizona.edu/intranet/papers/Textual\%20Analysis\%20of\%20Stock\%20Market.pdf}
    {Textual Analysis of Stock Market Prediction Using Financial News Articles}
  approaches this challenge from a very similar direction. There research
  has shown that text information can provide a 1\% to 2\% increase in accuracy of
  predicting the change in a stock price than a purely regressive model ~\cite{arizona}.
\instructions{Has there been any prior work on this task? If so,
  provide references where available}

\section*{Data}
  For the purpose of this project we have set up a \href{http://lucene.apache.org/solr/}{solr} instance to use as our datasource and text computing platform to handle the large amounts of data.  We split our data into three datasets.  This solr instance is currently deployed to \href{http://solr.deepdishdev.com:8983/solr}{solr.deepdishdev.com/solr}.

  \begin{itemize}
  	\item \textbf{Stock history}
		- This dataset will represent the historical stock data going back to 2001 for all stocks available on Yahoo's financial data platform (~24,000 stocks). This historical information was retrieved via the  \href{https://developer.yahoo.com/yql}{Yahoo data platform}.
	\item \textbf{Stocks}
		- This dataset is a listing of all stocks currently available on the Yahoo financial data platform and also the categories and indexes they are associated with.  This index also contains the current aliases for each stock as well.
	\item \textbf{News Articles}
		- The dataset is a collection of news articles that have been retrieved from various website via web page scraping.  Currently this dataset is made up of content from:
		\begin{itemize}
			\item \href{http://www.newsmax.com/archives/}{newsmax.com}
		\end{itemize}
  \end{itemize}

\section*{Assumptions}
  \begin{itemize}
  \item News articles lead stock price changes.
  \item A given news article relates to $n$ publicly traded companies or aliases for that company (i.e. company name, former company names)
  \end{itemize}
  Note: These assumptions are not necessarily accurate.

\instructions{Do you have data to train and test your system on? How
  will you evaluate your system?}

\section*{Evaluation}
  We will evaluate our system by measuring the accuracy of the forecasted
  stock prices on test data.

\section*{Our approach}
To find relevant articles we were required to search the articles for a given ticker name and retrieve results whether the ticker was present or the name of the company.  We used a synonyms file generated from the tickers that were present in the stocks dataset. We also used an implementation of the Porter Stemmer algorithm (\href{http://tartarus.org/~martin/PorterStemmer/}{http://tartarus.org/~martin/PorterStemmer/}) to improve search results. \\ \\  
Using our three datasets we will create a fourth composite dataset that will be a document set that contains an article, the most relevant ticker, and the history for the day following the release of the article.  We use a set of synonyms generated from our stock stockers from   For a given query and a document we calculate the score using cosine similarity \\ \\ 
  \[ 
  	score(q,d) = cosine\_similarity(q,d) = \frac{ V(q) \cdot V(d) }{ | V(q) | | V(d) | } 
\]
where \(V\) is a mapping function that translates both the query and document to a search vector \\ \\
 To find the most relevant ticker we will find the ticker for each article that has the highest correlated score.  This will give us a new composite dataset which we will use as our training and test data for our algorithm. \\ \\
  We will separate our joined news articles into test and training sets. For the training news
  articles, we will find the $n$ companies referred to in the article by taking a given
  list of companies and checking it is "matched" in the article. For example, we will
  take company names and their aliases and check for text similarity score for a given
  document. Once an article is mapped to a document, we will look up the $\%\delta$ in
  the stock price on the day the article was published. Accordingly, we will remove references
  to the company from the body of the document. For given test document the $\%\delta$
  will be calculated by using the K nearest documents using text similarity
  and taking the median $\%\delta$ of those documents.
  \begin{itemize}
    \item \href{ https://github.com/stockit } { Stockit Open Source Repositories }
  \end{itemize}
\instructions{Describe how you want to tackle this task}

\section*{To-Do list}
\instructions{Get started by making a to-do list. If you have a group
  project: who will do what? Set yourself deadlines. Here are a few
  items that might appear on your to-do list}
\begin{enumerate}
\item Retrieve news articles from other websites
	\begin{itemize}
		\item \href{ http://seekingalpha.com/ } { seeking alpha }
	\end{itemize}
\item We have not currently looked up any related work.
\item We will use am off the shelf KNN implementation.
\item We plan to check the validity of the algorithm and also explore some possible
  extensions. What if document map to an industry instead and stock are also related
  to industries?
\item Finish write up.
\end{enumerate}

\section*{Bibliography}
\bibliography{CS446projProposal}{}
\bibliographystyle{plain}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
